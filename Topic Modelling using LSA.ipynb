{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7341cf73",
   "metadata": {},
   "source": [
    "# Topic Modelling using LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e3bd6",
   "metadata": {},
   "source": [
    "Algoritma LSA (Latent Semantic Analysis) adalah salah satu algoritma yang dapat digunakan untuk menganalisa hubungan antara sebuah frase/kalimat dengan sekumpulan dokumen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd96963",
   "metadata": {},
   "source": [
    "Pada program ini akan menggunakan data abstrak dari portal tugas akhir trunojoyo program studi Teknik Informatika (https://pta.trunojoyo.ac.id/c_search/byprod/10), berikut code untuk melakukan crawling data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9245741b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install library beautifulsoup4 untuk melakukan crawling data\n",
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# membuat list, dataAbstract untuk menampung data sementara setelah crawling\n",
    "# dataFix untuk menampung data yang sudah ditambahkan kolom index dan siap di convert ke csv\n",
    "dataAbstract = []\n",
    "dataFix = []\n",
    "\n",
    "# function crawlAbstract untuk mengambil data judul dan abstract dari halaman detail pta trunojoyo teknik informatika\n",
    "def crawlAbstract(src):\n",
    "    # inisialisasi beautifulsoup4     \n",
    "    global c\n",
    "    tmp = []\n",
    "    page = requests.get(src)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # mengambil data judul     \n",
    "    title = soup.find(class_=\"title\").getText()\n",
    "    tmp.append(title)\n",
    "    \n",
    "    # mengambil data abstract     \n",
    "    abstractText = soup.p.getText()\n",
    "    tmp.append(abstractText)\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "# function getLinkToAbstract digunakan untuk mengambil data link menuju halaman detail\n",
    "# parameter src berisi link halaman daftar tugas akhir\n",
    "def getLinkToAbstract(src):\n",
    "    # inisialisasi beautifulsoup4\n",
    "    global c\n",
    "    page = requests.get(src)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # mendapatkan semua link menuju halaman detail\n",
    "    items = soup.find(class_=\"items\").find_all('a')\n",
    "    # looping setiap link untuk mendapatkan nilai href, \n",
    "    # link tersebut digunakan sebagai parameter function crawlAbstract agar mendapat data judul dan abstract\n",
    "    for item in items:\n",
    "        if item.get('href') != '#':\n",
    "            tmp = crawlAbstract(item.get('href'))\n",
    "            # dataAbstract menampung data sementara hasil crawl\n",
    "            dataAbstract.append(tmp)\n",
    "\n",
    "\n",
    "# link halaman pta trunojoyo prodi teknik informatika yang akan di crawl\n",
    "# halaman ini berisi daftar tugas akhir\n",
    "link = \"https://pta.trunojoyo.ac.id/c_search/byprod/10\"\n",
    "# mengambil data sampai halaman 100\n",
    "for i in range(1, 101):\n",
    "    # memindah halaman menuju halaman selanjutnya     \n",
    "    src = f\"https://pta.trunojoyo.ac.id/c_search/byprod/10/{i}\"\n",
    "    # counter untuk melihat progress berapa persen proses crawling\n",
    "    print(f\"Proses-{i}%\")\n",
    "    # memanggil function getLinkToAbstract untuk mendapatkan setiap link ke halaman detail\n",
    "    getLinkToAbstract(src)\n",
    "\n",
    "# setelah memperoleh semua data abstract, data tersebut ditampung di list dataAbstract\n",
    "# data perlu ditambahkan kolom index sebagai id\n",
    "# looping berikut bertujuan menambahkan kolom index di setiap baris, lalu disimpan di list dataFix\n",
    "for i in range(1, len(dataAbstract)+1):\n",
    "    dataAbstract[i-1].insert(0, i)\n",
    "    dataFix.append(dataAbstract[i-1])\n",
    "\n",
    "# menyimpan data hasil crawl dengan format csv\n",
    "header = ['index', 'title','abstract']\n",
    "with open('dataHasilCrawl.csv', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(header)\n",
    "    write.writerows(dataFix)\n",
    "# akan ada file dataHasilCrawl.csv berisi id, judul dan abtrak dari pta trunojoyo teknik informatika sejumlah 500 record\n",
    "# proses crawling selesai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c254a0a",
   "metadata": {},
   "source": [
    "Tahap selanjutnya melakukan pre-processing data dengan tahapan 1.punctuation removal 2.stemming\n",
    "1. punctuation removal adalah proses membersihkan teks dari tanda baca dan angka\n",
    "2. Stemming adalah proses pemetaan dan penguraian bentuk dari suatu kata menjadi bentuk kata dasarnya. Sederhananya, proses mengubah kata berimbuhan menjadi kata dasar, misal kata \"membosankan\" menjadi \"bosan\"\n",
    "3. Stopwords merupakan kata yang diabaikan dalam pemrosesan karena termasuk kata umum yang mempunyai fungsi tapi tidak mempunyai arti.Maksud dari kata umum adalah kata yang frekuensi kemunculannya tinggi, misalnya kata penghubung seperti “dan”, “atau”, “tapi”, “akan” dan lainnya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd4de96",
   "metadata": {},
   "source": [
    "Install terlebih dahulu library yang akan digunakan:\n",
    "Sastrawi digunakan untuk proses stemming dan stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282ffc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc59895b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses:1/500\n",
      "Proses:2/500\n",
      "Proses:3/500\n",
      "Proses:4/500\n",
      "Proses:5/500\n",
      "Proses:6/500\n",
      "Proses:7/500\n",
      "Proses:8/500\n",
      "Proses:9/500\n",
      "Proses:10/500\n",
      "Proses:11/500\n",
      "Proses:12/500\n",
      "Proses:13/500\n",
      "Proses:14/500\n",
      "Proses:15/500\n",
      "Proses:16/500\n",
      "Proses:17/500\n",
      "Proses:18/500\n",
      "Proses:19/500\n",
      "Proses:20/500\n",
      "Proses:21/500\n",
      "Proses:22/500\n",
      "Proses:23/500\n",
      "Proses:24/500\n",
      "Proses:25/500\n",
      "Proses:26/500\n",
      "Proses:27/500\n",
      "Proses:28/500\n",
      "Proses:29/500\n",
      "Proses:30/500\n",
      "Proses:31/500\n",
      "Proses:32/500\n",
      "Proses:33/500\n",
      "Proses:34/500\n",
      "Proses:35/500\n",
      "Proses:36/500\n",
      "Proses:37/500\n",
      "Proses:38/500\n",
      "Proses:39/500\n",
      "Proses:40/500\n",
      "Proses:41/500\n",
      "Proses:42/500\n",
      "Proses:43/500\n",
      "Proses:44/500\n",
      "Proses:45/500\n",
      "Proses:46/500\n",
      "Proses:47/500\n",
      "Proses:48/500\n",
      "Proses:49/500\n",
      "Proses:50/500\n",
      "Proses:51/500\n",
      "Proses:52/500\n",
      "Proses:53/500\n",
      "Proses:54/500\n",
      "Proses:55/500\n",
      "Proses:56/500\n",
      "Proses:57/500\n",
      "Proses:58/500\n",
      "Proses:59/500\n",
      "Proses:60/500\n",
      "Proses:61/500\n",
      "Proses:62/500\n",
      "Proses:63/500\n",
      "Proses:64/500\n",
      "Proses:65/500\n",
      "Proses:66/500\n",
      "Proses:67/500\n",
      "Proses:68/500\n",
      "Proses:69/500\n",
      "Proses:70/500\n",
      "Proses:71/500\n",
      "Proses:72/500\n",
      "Proses:73/500\n",
      "Proses:74/500\n",
      "Proses:75/500\n",
      "Proses:76/500\n",
      "Proses:77/500\n",
      "Proses:78/500\n",
      "Proses:79/500\n",
      "Proses:80/500\n",
      "Proses:81/500\n",
      "Proses:82/500\n",
      "Proses:83/500\n",
      "Proses:84/500\n",
      "Proses:85/500\n",
      "Proses:86/500\n",
      "Proses:87/500\n",
      "Proses:88/500\n",
      "Proses:89/500\n",
      "Proses:90/500\n",
      "Proses:91/500\n",
      "Proses:92/500\n",
      "Proses:93/500\n",
      "Proses:94/500\n",
      "Proses:95/500\n",
      "Proses:96/500\n",
      "Proses:97/500\n",
      "Proses:98/500\n",
      "Proses:99/500\n",
      "Proses:100/500\n",
      "Proses:101/500\n",
      "Proses:102/500\n",
      "Proses:103/500\n",
      "Proses:104/500\n",
      "Proses:105/500\n",
      "Proses:106/500\n",
      "Proses:107/500\n",
      "Proses:108/500\n",
      "Proses:109/500\n",
      "Proses:110/500\n",
      "Proses:111/500\n",
      "Proses:112/500\n",
      "Proses:113/500\n",
      "Proses:114/500\n",
      "Proses:115/500\n",
      "Proses:116/500\n",
      "Proses:117/500\n",
      "Proses:118/500\n",
      "Proses:119/500\n",
      "Proses:120/500\n",
      "Proses:121/500\n",
      "Proses:122/500\n",
      "Proses:123/500\n",
      "Proses:124/500\n",
      "Proses:125/500\n",
      "Proses:126/500\n",
      "Proses:127/500\n",
      "Proses:128/500\n",
      "Proses:129/500\n",
      "Proses:130/500\n",
      "Proses:131/500\n",
      "Proses:132/500\n",
      "Proses:133/500\n",
      "Proses:134/500\n",
      "Proses:135/500\n",
      "Proses:136/500\n",
      "Proses:137/500\n",
      "Proses:138/500\n",
      "Proses:139/500\n",
      "Proses:140/500\n",
      "Proses:141/500\n",
      "Proses:142/500\n",
      "Proses:143/500\n",
      "Proses:144/500\n",
      "Proses:145/500\n",
      "Proses:146/500\n",
      "Proses:147/500\n",
      "Proses:148/500\n",
      "Proses:149/500\n",
      "Proses:150/500\n",
      "Proses:151/500\n",
      "Proses:152/500\n",
      "Proses:153/500\n",
      "Proses:154/500\n",
      "Proses:155/500\n",
      "Proses:156/500\n",
      "Proses:157/500\n",
      "Proses:158/500\n",
      "Proses:159/500\n",
      "Proses:160/500\n",
      "Proses:161/500\n",
      "Proses:162/500\n",
      "Proses:163/500\n",
      "Proses:164/500\n",
      "Proses:165/500\n",
      "Proses:166/500\n",
      "Proses:167/500\n",
      "Proses:168/500\n",
      "Proses:169/500\n",
      "Proses:170/500\n",
      "Proses:171/500\n",
      "Proses:172/500\n",
      "Proses:173/500\n",
      "Proses:174/500\n",
      "Proses:175/500\n",
      "Proses:176/500\n",
      "Proses:177/500\n",
      "Proses:178/500\n",
      "Proses:179/500\n",
      "Proses:180/500\n",
      "Proses:181/500\n",
      "Proses:182/500\n",
      "Proses:183/500\n",
      "Proses:184/500\n",
      "Proses:185/500\n",
      "Proses:186/500\n",
      "Proses:187/500\n",
      "Proses:188/500\n",
      "Proses:189/500\n",
      "Proses:190/500\n",
      "Proses:191/500\n",
      "Proses:192/500\n",
      "Proses:193/500\n",
      "Proses:194/500\n",
      "Proses:195/500\n",
      "Proses:196/500\n",
      "Proses:197/500\n",
      "Proses:198/500\n",
      "Proses:199/500\n",
      "Proses:200/500\n",
      "Proses:201/500\n",
      "Proses:202/500\n",
      "Proses:203/500\n",
      "Proses:204/500\n",
      "Proses:205/500\n",
      "Proses:206/500\n",
      "Proses:207/500\n",
      "Proses:208/500\n",
      "Proses:209/500\n",
      "Proses:210/500\n",
      "Proses:211/500\n",
      "Proses:212/500\n",
      "Proses:213/500\n",
      "Proses:214/500\n",
      "Proses:215/500\n",
      "Proses:216/500\n",
      "Proses:217/500\n",
      "Proses:218/500\n",
      "Proses:219/500\n",
      "Proses:220/500\n",
      "Proses:221/500\n",
      "Proses:222/500\n",
      "Proses:223/500\n",
      "Proses:224/500\n",
      "Proses:225/500\n",
      "Proses:226/500\n",
      "Proses:227/500\n",
      "Proses:228/500\n",
      "Proses:229/500\n",
      "Proses:230/500\n",
      "Proses:231/500\n",
      "Proses:232/500\n",
      "Proses:233/500\n",
      "Proses:234/500\n",
      "Proses:235/500\n",
      "Proses:236/500\n",
      "Proses:237/500\n",
      "Proses:238/500\n",
      "Proses:239/500\n",
      "Proses:240/500\n",
      "Proses:241/500\n",
      "Proses:242/500\n",
      "Proses:243/500\n",
      "Proses:244/500\n",
      "Proses:245/500\n",
      "Proses:246/500\n",
      "Proses:247/500\n",
      "Proses:248/500\n",
      "Proses:249/500\n",
      "Proses:250/500\n",
      "Proses:251/500\n",
      "Proses:252/500\n",
      "Proses:253/500\n",
      "Proses:254/500\n",
      "Proses:255/500\n",
      "Proses:256/500\n",
      "Proses:257/500\n",
      "Proses:258/500\n",
      "Proses:259/500\n",
      "Proses:260/500\n",
      "Proses:261/500\n",
      "Proses:262/500\n",
      "Proses:263/500\n",
      "Proses:264/500\n",
      "Proses:265/500\n",
      "Proses:266/500\n",
      "Proses:267/500\n",
      "Proses:268/500\n",
      "Proses:269/500\n",
      "Proses:270/500\n",
      "Proses:271/500\n",
      "Proses:272/500\n",
      "Proses:273/500\n",
      "Proses:274/500\n",
      "Proses:275/500\n",
      "Proses:276/500\n",
      "Proses:277/500\n",
      "Proses:278/500\n",
      "Proses:279/500\n",
      "Proses:280/500\n",
      "Proses:281/500\n",
      "Proses:282/500\n",
      "Proses:283/500\n",
      "Proses:284/500\n",
      "Proses:285/500\n",
      "Proses:286/500\n",
      "Proses:287/500\n",
      "Proses:288/500\n",
      "Proses:289/500\n",
      "Proses:290/500\n",
      "Proses:291/500\n",
      "Proses:292/500\n",
      "Proses:293/500\n",
      "Proses:294/500\n",
      "Proses:295/500\n",
      "Proses:296/500\n",
      "Proses:297/500\n",
      "Proses:298/500\n",
      "Proses:299/500\n",
      "Proses:300/500\n",
      "Proses:301/500\n",
      "Proses:302/500\n",
      "Proses:303/500\n",
      "Proses:304/500\n",
      "Proses:305/500\n",
      "Proses:306/500\n",
      "Proses:307/500\n",
      "Proses:308/500\n",
      "Proses:309/500\n",
      "Proses:310/500\n",
      "Proses:311/500\n",
      "Proses:312/500\n",
      "Proses:313/500\n",
      "Proses:314/500\n",
      "Proses:315/500\n",
      "Proses:316/500\n",
      "Proses:317/500\n",
      "Proses:318/500\n",
      "Proses:319/500\n",
      "Proses:320/500\n",
      "Proses:321/500\n",
      "Proses:322/500\n",
      "Proses:323/500\n",
      "Proses:324/500\n",
      "Proses:325/500\n",
      "Proses:326/500\n",
      "Proses:327/500\n",
      "Proses:328/500\n",
      "Proses:329/500\n",
      "Proses:330/500\n",
      "Proses:331/500\n",
      "Proses:332/500\n",
      "Proses:333/500\n",
      "Proses:334/500\n",
      "Proses:335/500\n",
      "Proses:336/500\n",
      "Proses:337/500\n",
      "Proses:338/500\n",
      "Proses:339/500\n",
      "Proses:340/500\n",
      "Proses:341/500\n",
      "Proses:342/500\n",
      "Proses:343/500\n",
      "Proses:344/500\n",
      "Proses:345/500\n",
      "Proses:346/500\n",
      "Proses:347/500\n",
      "Proses:348/500\n",
      "Proses:349/500\n",
      "Proses:350/500\n",
      "Proses:351/500\n",
      "Proses:352/500\n",
      "Proses:353/500\n",
      "Proses:354/500\n",
      "Proses:355/500\n",
      "Proses:356/500\n",
      "Proses:357/500\n",
      "Proses:358/500\n",
      "Proses:359/500\n",
      "Proses:360/500\n",
      "Proses:361/500\n",
      "Proses:362/500\n",
      "Proses:363/500\n",
      "Proses:364/500\n",
      "Proses:365/500\n",
      "Proses:366/500\n",
      "Proses:367/500\n",
      "Proses:368/500\n",
      "Proses:369/500\n",
      "Proses:370/500\n",
      "Proses:371/500\n",
      "Proses:372/500\n",
      "Proses:373/500\n",
      "Proses:374/500\n",
      "Proses:375/500\n",
      "Proses:376/500\n",
      "Proses:377/500\n",
      "Proses:378/500\n",
      "Proses:379/500\n",
      "Proses:380/500\n",
      "Proses:381/500\n",
      "Proses:382/500\n",
      "Proses:383/500\n",
      "Proses:384/500\n",
      "Proses:385/500\n",
      "Proses:386/500\n",
      "Proses:387/500\n",
      "Proses:388/500\n",
      "Proses:389/500\n",
      "Proses:390/500\n",
      "Proses:391/500\n",
      "Proses:392/500\n",
      "Proses:393/500\n",
      "Proses:394/500\n",
      "Proses:395/500\n",
      "Proses:396/500\n",
      "Proses:397/500\n",
      "Proses:398/500\n",
      "Proses:399/500\n",
      "Proses:400/500\n",
      "Proses:401/500\n",
      "Proses:402/500\n",
      "Proses:403/500\n",
      "Proses:404/500\n",
      "Proses:405/500\n",
      "Proses:406/500\n",
      "Proses:407/500\n",
      "Proses:408/500\n",
      "Proses:409/500\n",
      "Proses:410/500\n",
      "Proses:411/500\n",
      "Proses:412/500\n",
      "Proses:413/500\n",
      "Proses:414/500\n",
      "Proses:415/500\n",
      "Proses:416/500\n",
      "Proses:417/500\n",
      "Proses:418/500\n",
      "Proses:419/500\n",
      "Proses:420/500\n",
      "Proses:421/500\n",
      "Proses:422/500\n",
      "Proses:423/500\n",
      "Proses:424/500\n",
      "Proses:425/500\n",
      "Proses:426/500\n",
      "Proses:427/500\n",
      "Proses:428/500\n",
      "Proses:429/500\n",
      "Proses:430/500\n",
      "Proses:431/500\n",
      "Proses:432/500\n",
      "Proses:433/500\n",
      "Proses:434/500\n",
      "Proses:435/500\n",
      "Proses:436/500\n",
      "Proses:437/500\n",
      "Proses:438/500\n",
      "Proses:439/500\n",
      "Proses:440/500\n",
      "Proses:441/500\n",
      "Proses:442/500\n",
      "Proses:443/500\n",
      "Proses:444/500\n",
      "Proses:445/500\n",
      "Proses:446/500\n",
      "Proses:447/500\n",
      "Proses:448/500\n",
      "Proses:449/500\n",
      "Proses:450/500\n",
      "Proses:451/500\n",
      "Proses:452/500\n",
      "Proses:453/500\n",
      "Proses:454/500\n",
      "Proses:455/500\n",
      "Proses:456/500\n",
      "Proses:457/500\n",
      "Proses:458/500\n",
      "Proses:459/500\n",
      "Proses:460/500\n",
      "Proses:461/500\n",
      "Proses:462/500\n",
      "Proses:463/500\n",
      "Proses:464/500\n",
      "Proses:465/500\n",
      "Proses:466/500\n",
      "Proses:467/500\n",
      "Proses:468/500\n",
      "Proses:469/500\n",
      "Proses:470/500\n",
      "Proses:471/500\n",
      "Proses:472/500\n",
      "Proses:473/500\n",
      "Proses:474/500\n",
      "Proses:475/500\n",
      "Proses:476/500\n",
      "Proses:477/500\n",
      "Proses:478/500\n",
      "Proses:479/500\n",
      "Proses:480/500\n",
      "Proses:481/500\n",
      "Proses:482/500\n",
      "Proses:483/500\n",
      "Proses:484/500\n",
      "Proses:485/500\n",
      "Proses:486/500\n",
      "Proses:487/500\n",
      "Proses:488/500\n",
      "Proses:489/500\n",
      "Proses:490/500\n",
      "Proses:491/500\n",
      "Proses:492/500\n",
      "Proses:493/500\n",
      "Proses:494/500\n",
      "Proses:495/500\n",
      "Proses:496/500\n",
      "Proses:497/500\n",
      "Proses:498/500\n",
      "Proses:499/500\n",
      "Proses:500/500\n"
     ]
    }
   ],
   "source": [
    "import csv # untuk menyimpan hasil dalam format csv\n",
    "import string \n",
    "import re # re : digunakan untuk proses punctuation removal\n",
    "\n",
    "# memanggil function yang digunakan\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "# membuat list untuk menampung data\n",
    "dataAbstract = []\n",
    "dataAfterPreprocessing = []\n",
    "\n",
    "# inisialisasi library sastrawi untuk stemming\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# inisialisasi library sastrawi untuk proses stopword removal\n",
    "factory2 = StopWordRemoverFactory()\n",
    "stopword = factory2.create_stop_word_remover()\n",
    "\n",
    "# untuk counter proses\n",
    "count = 1\n",
    "\n",
    "# membaca data dari proses sebelumnya\n",
    "with open(\"dataHasilCrawl.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader, None)\n",
    "    for row in reader:\n",
    "        if len(row) != 0:\n",
    "#           data sebelum proses disimpan pada list dataAbstract\n",
    "            dataAbstract.append(row)\n",
    "\n",
    "# looping untuk memproses setiap data\n",
    "for abstract in dataAbstract:\n",
    "#   ambil data\n",
    "    tmp = abstract.pop()\n",
    "#   lakukan case folding (mengubah teks menjadi bentuk standar: huruf kecil)\n",
    "    tmp = tmp.lower()\n",
    "#   menghapus angka\n",
    "    tmp = re.sub(r\"\\d+\", \"\", tmp)\n",
    "#   menghapus tanda baca\n",
    "    tmp = tmp.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "#   menghapus whitespace\n",
    "    tmp = tmp.strip()\n",
    "    tmp = re.sub('\\s+',' ',tmp)\n",
    "#   melakukan proses stemming\n",
    "#     tmp = stemmer.stem(tmp)\n",
    "#   melakukan proses stopword removal\n",
    "    tmp = stopword.remove(tmp)\n",
    "#   menambahkan data ke list dataAfterPreprocessing\n",
    "    abstract.append(tmp)\n",
    "    dataAfterPreprocessing.append(abstract)\n",
    "#   print counter proses\n",
    "    print(f\"Proses:{count}/{len(dataAbstract)}\")\n",
    "    count+=1\n",
    "\n",
    "# menyimpan data dari list dataAfterPreprocessing ke bentuk csv\n",
    "header = ['index', 'title','abstract_cleaned']\n",
    "with open('dataAfterPreprocessing.csv', 'w', encoding=\"utf-8\") as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(header)\n",
    "    write.writerows(dataAfterPreprocessing)\n",
    "# akan ada file dataAfterPreprocessing.csv berisi id, judul, abtract yang sudah dipreprocessing\n",
    "# preprocessing sudah selesai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9da9b3",
   "metadata": {},
   "source": [
    "Masuk ke tahap penerapan LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47fe448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1cd3ac1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9537fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a74f65f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\lenovo-\n",
      "[nltk_data]     pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14236991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words=set(nltk.corpus.stopwords.words('indonesian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45547a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE \\...</td>\n",
       "      <td>sistem informasi akademik siakad merupakan sis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>APLIKASI KONTROL DAN MONITORING JARINGAN KOMPU...</td>\n",
       "      <td>berjalannya koneksi jaringan komputer lancar g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>RANCANG BANGUN APLIKASI PROXY SERVER UNTUK\\r\\n...</td>\n",
       "      <td>web server sebuah perangkat lunak server berfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SISTEM PENDUKUNG KEPUTUSAN OPTIMASI PENJADWALA...</td>\n",
       "      <td>penjadwalan kuliah perguruan tinggi merupakan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SISTEM AUGMENTED REALITY ANIMASI BENDA BERGERA...</td>\n",
       "      <td>seiring perkembangan teknologi ada didunia mun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              title  \\\n",
       "0      1  PERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE \\...   \n",
       "1      2  APLIKASI KONTROL DAN MONITORING JARINGAN KOMPU...   \n",
       "2      3  RANCANG BANGUN APLIKASI PROXY SERVER UNTUK\\r\\n...   \n",
       "3      4  SISTEM PENDUKUNG KEPUTUSAN OPTIMASI PENJADWALA...   \n",
       "4      5  SISTEM AUGMENTED REALITY ANIMASI BENDA BERGERA...   \n",
       "\n",
       "                                    abstract_cleaned  \n",
       "0  sistem informasi akademik siakad merupakan sis...  \n",
       "1  berjalannya koneksi jaringan komputer lancar g...  \n",
       "2  web server sebuah perangkat lunak server berfu...  \n",
       "3  penjadwalan kuliah perguruan tinggi merupakan ...  \n",
       "4  seiring perkembangan teknologi ada didunia mun...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./dataAfterPreprocessing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeeb7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the publish date.\n",
    "df.drop(['index'],axis=1,inplace=True)\n",
    "# drop the publish date.\n",
    "df.drop(['title'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35a46568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sistem informasi akademik siakad merupakan sis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>berjalannya koneksi jaringan komputer lancar g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>web server sebuah perangkat lunak server berfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>penjadwalan kuliah perguruan tinggi merupakan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seiring perkembangan teknologi ada didunia mun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gerak pekerja game memiliki genre rts realtime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>perkembangan game semakin pesat memberikan ber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sistem pengenalan wajah suatu sistem mengenali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>teknologi mobile game beroperating system open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kantor badan kepegawaian kota bangkalan instan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    abstract_cleaned\n",
       "0  sistem informasi akademik siakad merupakan sis...\n",
       "1  berjalannya koneksi jaringan komputer lancar g...\n",
       "2  web server sebuah perangkat lunak server berfu...\n",
       "3  penjadwalan kuliah perguruan tinggi merupakan ...\n",
       "4  seiring perkembangan teknologi ada didunia mun...\n",
       "5  gerak pekerja game memiliki genre rts realtime...\n",
       "6  perkembangan game semakin pesat memberikan ber...\n",
       "7  sistem pengenalan wajah suatu sistem mengenali...\n",
       "8  teknologi mobile game beroperating system open...\n",
       "9  kantor badan kepegawaian kota bangkalan instan..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86c9b5b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vect =TfidfVectorizer(stop_words=stop_words,max_features=1000) # to play with. min_df,max_df,max_features etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9422194",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_text=vect.fit_transform(df['abstract_cleaned'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a269b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1000)\n",
      "  (0, 354)\t0.1184936369291229\n",
      "  (0, 196)\t0.13956580648376873\n",
      "  (0, 684)\t0.1343875919276184\n",
      "  (0, 179)\t0.12133616214140663\n",
      "  (0, 395)\t0.13685884977996102\n",
      "  (0, 732)\t0.09114832069093537\n",
      "  (0, 867)\t0.10565655947056028\n",
      "  (0, 168)\t0.11032302056697307\n",
      "  (0, 475)\t0.09813888102756477\n",
      "  (0, 923)\t0.3081480905267873\n",
      "  (0, 688)\t0.09813888102756477\n",
      "  (0, 392)\t0.1280499695101433\n",
      "  (0, 366)\t0.13211425507553565\n",
      "  (0, 503)\t0.06227680213408083\n",
      "  (0, 404)\t0.12287175495399294\n",
      "  (0, 929)\t0.1343875919276184\n",
      "  (0, 791)\t0.24267232428281327\n",
      "  (0, 808)\t0.13211425507553565\n",
      "  (0, 329)\t0.09684767920074258\n",
      "  (0, 131)\t0.14898423918366568\n",
      "  (0, 953)\t0.11987935314799347\n",
      "  (0, 784)\t0.047360434797127454\n",
      "  (0, 99)\t0.11242780173976039\n",
      "  (0, 583)\t0.08272067498544265\n",
      "  (0, 365)\t0.13685884977996102\n",
      "  :\t:\n",
      "  (499, 351)\t0.06266569569742468\n",
      "  (499, 39)\t0.0923587589179502\n",
      "  (499, 30)\t0.20311354251553534\n",
      "  (499, 697)\t0.05266064595121842\n",
      "  (499, 117)\t0.0938974226708933\n",
      "  (499, 965)\t0.08733535401212822\n",
      "  (499, 689)\t0.12891129588582412\n",
      "  (499, 80)\t0.03838775159920479\n",
      "  (499, 821)\t0.033341983518634946\n",
      "  (499, 745)\t0.07326991657592176\n",
      "  (499, 88)\t0.07004309923827863\n",
      "  (499, 986)\t0.09756800783423276\n",
      "  (499, 796)\t0.0956756218728135\n",
      "  (499, 912)\t0.19561296559779046\n",
      "  (499, 730)\t0.058931914021214026\n",
      "  (499, 596)\t0.07386147869391585\n",
      "  (499, 281)\t0.05440941183601676\n",
      "  (499, 159)\t0.057828573261397814\n",
      "  (499, 36)\t0.1275545719269735\n",
      "  (499, 76)\t0.15555037274153827\n",
      "  (499, 86)\t0.07510399111638014\n",
      "  (499, 732)\t0.0637201925837372\n",
      "  (499, 131)\t0.0347174229898487\n",
      "  (499, 462)\t0.20722310799032384\n",
      "  (499, 81)\t0.0838055535362557\n"
     ]
    }
   ],
   "source": [
    "print(vect_text.shape)\n",
    "print(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d77e063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf=vect.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "810ccedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasil telapak\n",
      "1.3701673260271405\n",
      "6.523458920524919\n"
     ]
    }
   ],
   "source": [
    "dd=dict(zip(vect.get_feature_names(), idf))\n",
    "l=sorted(dd, key=(dd).get)\n",
    "# print(l)\n",
    "print(l[0],l[-1])\n",
    "print(dd['hasil'])\n",
    "print(dd['telapak'])  # police is most common and forecast is least common among the news headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4dc3f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=10, random_state=42)\n",
    "\n",
    "lsa_top=lsa_model.fit_transform(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e9dbc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25314743 -0.07926497 -0.15779302 ...  0.07078405 -0.15720191\n",
      "   0.08248597]\n",
      " [ 0.08594745 -0.03921934 -0.01889975 ... -0.0277596  -0.07017209\n",
      "  -0.03474838]\n",
      " [ 0.10875014 -0.05476071 -0.01671957 ...  0.27305754 -0.01860027\n",
      "  -0.00717952]\n",
      " ...\n",
      " [ 0.21358561 -0.01412773 -0.09962852 ... -0.23532446  0.11006678\n",
      "   0.23077264]\n",
      " [ 0.28543252 -0.044966   -0.11713009 ... -0.01439869  0.01721985\n",
      "  -0.06424741]\n",
      " [ 0.19844412 -0.07808743  0.01047994 ...  0.01968828  0.01092608\n",
      "  -0.10894619]]\n",
      "(500, 10)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_top)\n",
    "print(lsa_top.shape)  # (no_of_doc*no_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da02a41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Topic  0  :  25.314742581593652\n",
      "Topic  1  :  -7.92649675944443\n",
      "Topic  2  :  -15.779302240752369\n",
      "Topic  3  :  -14.716978564412589\n",
      "Topic  4  :  3.1661880386549996\n",
      "Topic  5  :  -10.053559857839996\n",
      "Topic  6  :  5.665605564559997\n",
      "Topic  7  :  7.078404802169859\n",
      "Topic  8  :  -15.720191082463902\n",
      "Topic  9  :  8.248596705601583\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,topic in enumerate(l):\n",
    "    print(\"Topic \",i,\" : \",topic*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bde57663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1000)\n",
      "[[ 0.01990259  0.00868318  0.01116126 ...  0.0112083   0.00893897\n",
      "   0.01253246]\n",
      " [-0.01279456  0.00508693  0.00048887 ... -0.00664785 -0.0040516\n",
      "  -0.00555939]\n",
      " [-0.00221451 -0.00221382 -0.00424869 ... -0.00809025 -0.00825992\n",
      "  -0.01063404]\n",
      " ...\n",
      " [-0.00339135  0.00548564  0.00708094 ...  0.01098567 -0.01600809\n",
      "  -0.02055816]\n",
      " [ 0.00294209  0.0022143   0.00645995 ...  0.01137881  0.0334048\n",
      "   0.05155663]\n",
      " [-0.0035613  -0.00520553 -0.00259026 ...  0.00077315 -0.03029028\n",
      "  -0.04712787]]\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape) # (no_of_topics*no_of_words)\n",
    "print(lsa_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "929e9486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "citra sistem data metode game siswa nilai hasil informasi proses \n",
      "\n",
      "Topic 1: \n",
      "citra segmentasi fitur tahap wajah darah penyakit ekstraksi pembuluh akurasi \n",
      "\n",
      "Topic 2: \n",
      "game citra edukasi pembelajaran anak android permainan menarik matematika bahasa \n",
      "\n",
      "Topic 3: \n",
      "siswa keputusan kriteria pendukung beasiswa segmentasi game citra metode saw \n",
      "\n",
      "Topic 4: \n",
      "siswa pembelajaran elearning guru belajar sekolah media aplikasi materi bahasa \n",
      "\n",
      "Topic 5: \n",
      "wajah pengenalan siswa distance ekspresi analysis euclidean tangan pembelajaran training \n",
      "\n",
      "Topic 6: \n",
      "arsitektur perusahaan erp sistem zf driven penilaian enterprise model wajah \n",
      "\n",
      "Topic 7: \n",
      "beasiswa dokumen pencarian web bahasa informasi keputusan madura semantik sistem \n",
      "\n",
      "Topic 8: \n",
      "madura bahasa batik pembelajaran elearning belajar model indonesia perusahaan mahasiswa \n",
      "\n",
      "Topic 9: \n",
      "batik citra siswa warna pencarian sekolah tekstur isi game akademik \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcebf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
